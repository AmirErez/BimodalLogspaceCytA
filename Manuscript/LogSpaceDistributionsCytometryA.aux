\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{Vogel2016}
\citation{Parks2006}
\citation{Bagwell2016}
\citation{Finak2010}
\citation{Herzenberg2006}
\citation{Novo2008}
\citation{Friedman2006,Prill2015,Pal2015,Ridden2015,Mojtahedi2016,Erez2017}
\citation{Brown2010}
\citation{Prinz2010}
\citation{Friedman2006}
\citation{Feinerman2008,Pelkmans2012,Cotari2013}
\citation{Prill2015}
\citation{Friedman2006,Pal2015,Vogel2016}
\citation{Das2009}
\citation{Cron2013,ONeill2013,Anchang2014,Finak2014,Saeys2016,Chen2016}
\citation{Mukhopadhyay2000}
\citation{Vogel2016}
\newlabel{eq:P2Q}{{1}{7}{Methods - theory}{equation.0.1}{}}
\newlabel{eq:LogNormalMix}{{2}{7}{Methods - theory}{equation.0.2}{}}
\citation{Novo2008}
\citation{Silverman1981}
\citation{Johnsson2017}
\citation{Das2009}
\citation{Hartigan1985}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \textbf  {Log-normal mixture showing the mismatch in the number of peaks.} \textbf  {Top row, red:} $P(\mathop {\mathgroup \symoperators log}\nolimits I)$ vs. $\mathop {\mathgroup \symoperators log}\nolimits I$ normalized to max. \textbf  {Middle row, magenta:} $Q(I)$ vs. $I$ normalized to max, and plotted on a narrower range. \textbf  {Bottom row, blue:} $Q(I)$ vs. $\mathop {\mathgroup \symoperators log}\nolimits I$ normalized to max, rescaling the x-axis as in Ref.\nobreakspace  {}\cite  {Novo2008}. In the central column where $\sigma _1=\sigma _2=0.8$, $P(\mathop {\mathgroup \symoperators log}\nolimits I)$ shows explicit bimodality whereas $Q(I)$ is unimodal. \textbf  {Right column:} in this case, the variance $\sigma ^2$ is large enough (see Eq.\nobreakspace  {}\ref  {eq:Plogy3Maxima}) that $P(\mathop {\mathgroup \symoperators log}\nolimits I)$ has only one mode even though it is modeled as a mixture. In all cases: $I_1=100,\,I_2=1000,\,\alpha =0.5$ varying $\sigma _{1,2}=\{0.4,0.8,1.2\}$ (left to right columns, respectively). Leftmost column shows axes. \relax }}{8}{figure.caption.4}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:PlotsLinearLog}{{1}{8}{\textbf {Log-normal mixture showing the mismatch in the number of peaks.} \textbf {Top row, red:} $P(\log I)$ vs. $\log I$ normalized to max. \textbf {Middle row, magenta:} $Q(I)$ vs. $I$ normalized to max, and plotted on a narrower range. \textbf {Bottom row, blue:} $Q(I)$ vs. $\log I$ normalized to max, rescaling the x-axis as in Ref.~\cite {Novo2008}. In the central column where $\sigma _1=\sigma _2=0.8$, $P(\log I)$ shows explicit bimodality whereas $Q(I)$ is unimodal. \textbf {Right column:} in this case, the variance $\sigma ^2$ is large enough (see Eq.~\ref {eq:Plogy3Maxima}) that $P(\log I)$ has only one mode even though it is modeled as a mixture. In all cases: $I_1=100,\,I_2=1000,\,\alpha =0.5$ varying $\sigma _{1,2}=\{0.4,0.8,1.2\}$ (left to right columns, respectively). Leftmost column shows axes. \relax }{figure.caption.4}{}}
\newlabel{eq:extrema}{{3}{9}{Methods - theory}{equation.0.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces \textbf  {Graphical solution to count the number of extrema.} We test our peak counting method, based on the same equations as in Fig.\nobreakspace  {}\ref  {fig:PlotsLinearLog}, but with additional settings. (Vertical axis represents the functions $A, B_1,B_3$ according to the legend). When the red (blue) curves intersect the dashed black line, $P(\mathop {\mathgroup \symoperators log}\nolimits I)$ ($Q(I)$) are extremized. Dashed black: $A(y)$, blue: $B_1(y)$ and red: $B_3(y)$. The mismatch between the number of extrema of $P(\mathop {\mathgroup \symoperators log}\nolimits I)$ and $Q(I)$ is apparent when the red curve intersects $A$ at 3 points, whereas the blue curve only intersects $A$ once. In both cases, the loci of the extrema are different for the two distributions. The plots along the diagonal (which correspond to the cases in Fig.\nobreakspace  {}\ref  {fig:PlotsLinearLog}) show the case $\sigma _1=\sigma _2$ which simplifies $A(y)$ to a straight line (the general case being a parabola) in these axes.\relax }}{10}{figure.caption.5}}
\newlabel{fig:ExtremaSolutions}{{2}{10}{\textbf {Graphical solution to count the number of extrema.} We test our peak counting method, based on the same equations as in Fig.~\ref {fig:PlotsLinearLog}, but with additional settings. (Vertical axis represents the functions $A, B_1,B_3$ according to the legend). When the red (blue) curves intersect the dashed black line, $P(\log I)$ ($Q(I)$) are extremized. Dashed black: $A(y)$, blue: $B_1(y)$ and red: $B_3(y)$. The mismatch between the number of extrema of $P(\log I)$ and $Q(I)$ is apparent when the red curve intersects $A$ at 3 points, whereas the blue curve only intersects $A$ once. In both cases, the loci of the extrema are different for the two distributions. The plots along the diagonal (which correspond to the cases in Fig.~\ref {fig:PlotsLinearLog}) show the case $\sigma _1=\sigma _2$ which simplifies $A(y)$ to a straight line (the general case being a parabola) in these axes.\relax }{figure.caption.5}{}}
\newlabel{eq:Plogy3Maxima}{{4}{10}{Methods - theory}{equation.0.4}{}}
\newlabel{eq:QI3Maxima}{{5}{11}{Methods - theory}{equation.0.5}{}}
\citation{FlowJo}
\citation{FlowJo}
\citation{Feinerman2008}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces \textbf  {Analysis of experimental data reveals the effect we describe in a real scenario. }\textbf  {(A)} Histogram of ppERK as plotted by FlowJo \cite  {FlowJo}; \textbf  {(B)} Histograms for $P(\mathop {\mathgroup \symoperators log}\nolimits I)$ (red,dots) and $Q(I)$ (blue,dots) vs. $\mathop {\mathgroup \symoperators log}\nolimits I$ as estimated from the data binned logarithmically. Note that plotting $Q(I)$ vs. $\mathop {\mathgroup \symoperators log}\nolimits I$ is somewhat unusual but allows both $P$ and $Q$ to be plotted on the same axis. The red line shows the result of fitting $P(\mathop {\mathgroup \symoperators log}\nolimits I)$ to a gaussian mixture model (Eq.\nobreakspace  {}\ref  {eq:LogNormalMix}), and the blue line is the estimate for $Q(I)$ from $P(\mathop {\mathgroup \symoperators log}\nolimits I)$ according to Eq.\nobreakspace  {}\ref  {eq:P2Q}. The blue star indicates the location of the only maximum for $Q(I)$ obtained from Eq. \ref  {eq:extremaQ}, despite the obvious two maxima in $P(\mathop {\mathgroup \symoperators log}\nolimits I)$ (red). Hartigan's unimodality p-values for $\mathop {\mathgroup \symoperators log}\nolimits I$ (red) and $I$ (blue) are taken directly from the data without binning, corroborating that $\mathop {\mathgroup \symoperators log}\nolimits I$ is bimodal whereas $I$ is unimodal. \textbf  {(C)} (Vertical axis represents the functions $A, B_1,B_3$ according to the legend). Graphic solution of the extrema conditions as in Fig.\nobreakspace  {}\ref  {fig:ExtremaSolutions} explicitly reveals the three solutions for $P(\mathop {\mathgroup \symoperators log}\nolimits I_*)$ (red line intersects black dashed) as opposed to the single solution for $Q(I_*)$ (the blue line intersects the black dashed line up beyond the plotted area, solution also plotted as blue star in the middle plot), indicating that $Q(I)$ has only one mode.\relax }}{15}{figure.caption.10}}
\newlabel{fig:Experiment}{{3}{15}{\textbf {Analysis of experimental data reveals the effect we describe in a real scenario. }\textbf {(A)} Histogram of ppERK as plotted by FlowJo \cite {FlowJo}; \textbf {(B)} Histograms for $P(\log I)$ (red,dots) and $Q(I)$ (blue,dots) vs. $\log I$ as estimated from the data binned logarithmically. Note that plotting $Q(I)$ vs. $\log I$ is somewhat unusual but allows both $P$ and $Q$ to be plotted on the same axis. The red line shows the result of fitting $P(\log I)$ to a gaussian mixture model (Eq.~\ref {eq:LogNormalMix}), and the blue line is the estimate for $Q(I)$ from $P(\log I)$ according to Eq.~\ref {eq:P2Q}. The blue star indicates the location of the only maximum for $Q(I)$ obtained from Eq. \ref {eq:extremaQ}, despite the obvious two maxima in $P(\log I)$ (red). Hartigan's unimodality p-values for $\log I$ (red) and $I$ (blue) are taken directly from the data without binning, corroborating that $\log I$ is bimodal whereas $I$ is unimodal. \textbf {(C)} (Vertical axis represents the functions $A, B_1,B_3$ according to the legend). Graphic solution of the extrema conditions as in Fig.~\ref {fig:ExtremaSolutions} explicitly reveals the three solutions for $P(\log I_*)$ (red line intersects black dashed) as opposed to the single solution for $Q(I_*)$ (the blue line intersects the black dashed line up beyond the plotted area, solution also plotted as blue star in the middle plot), indicating that $Q(I)$ has only one mode.\relax }{figure.caption.10}{}}
\citation{botev2010}
\citation{Mukhopadhyay2000}
\citation{Spencer2009}
\citation{Koller2009}
\citation{Prill2015,Ching2017}
\citation{Filippi2016}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces \textbf  {Analysis of experimental data with two correlated measurements.} \textbf  {(A)} The joint distribution $P_2(\mathop {\mathgroup \symoperators log}\nolimits I_{ppERK},\mathop {\mathgroup \symoperators log}\nolimits I_{ERK1})$ as a heat map with its marginals plotted on the top and on its right. The correlation between ppERK and ERK1 levels is clear in the data. Dashed red (grey) lines are proposed manual gates according to the marginal (joint) distributions $P(\mathop {\mathgroup \symoperators log}\nolimits I_{ppERK})$ $\left (P_2(\mathop {\mathgroup \symoperators log}\nolimits I_{ppERK},\mathop {\mathgroup \symoperators log}\nolimits I_{ERK1})\right )$. \textbf  {(B)} Bayesian network depicted as a graphical model to show the flow of influence on the measurement of ppERK. The pair ERK1 and ppERK are in a template to suggest that there exist other pairs of correlated observables that depend on activation status and cell-to-cell variability.\relax }}{19}{figure.caption.11}}
\newlabel{fig:ppERKvsERK1heatmap}{{4}{19}{\textbf {Analysis of experimental data with two correlated measurements.} \textbf {(A)} The joint distribution $P_2(\log I_{ppERK},\log I_{ERK1})$ as a heat map with its marginals plotted on the top and on its right. The correlation between ppERK and ERK1 levels is clear in the data. Dashed red (grey) lines are proposed manual gates according to the marginal (joint) distributions $P(\log I_{ppERK})$ $\left (P_2(\log I_{ppERK},\log I_{ERK1})\right )$. \textbf {(B)} Bayesian network depicted as a graphical model to show the flow of influence on the measurement of ppERK. The pair ERK1 and ppERK are in a template to suggest that there exist other pairs of correlated observables that depend on activation status and cell-to-cell variability.\relax }{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces \textbf  {By dividing ppERK readings by ERK1, we can ameliorate the mismatch between the two representations.} \textbf  {(A)} $P(\mathop {\mathgroup \symoperators log}\nolimits I_{ppERK})$ and $Q(I_{ppERK})$ vs. $\mathop {\mathgroup \symoperators log}\nolimits I_{ppERK}$ (dots: data, lines: Gaussian mixture fit) together with \textbf  {(B)} their extrema analysis, showing that the second mode in log ppERK does not exist if the data is linearly binned. \textbf  {(C)} The same treatment but for $\mathaccent "707E\relax {I} = I_{ppERK}/I_{ERK1}$, \textbf  {(D)} shows that both $\mathaccent "707E\relax {I}$ and $\mathop {\mathgroup \symoperators log}\nolimits \mathaccent "707E\relax {I}$ have two modes, thus normalizing ppERK levels by total ERK1 maintains the bimodal structure both in $P(\mathop {\mathgroup \symoperators log}\nolimits \mathaccent "707E\relax {I})$ and in $Q(\mathaccent "707E\relax {I})$. In (B) and (D), the vertical axis represents the functions $A, B_1,B_3$ according to the legend.\relax }}{20}{figure.caption.12}}
\newlabel{fig:NormppERKbyERK}{{5}{20}{\textbf {By dividing ppERK readings by ERK1, we can ameliorate the mismatch between the two representations.} \textbf {(A)} $P(\log I_{ppERK})$ and $Q(I_{ppERK})$ vs. $\log I_{ppERK}$ (dots: data, lines: Gaussian mixture fit) together with \textbf {(B)} their extrema analysis, showing that the second mode in log ppERK does not exist if the data is linearly binned. \textbf {(C)} The same treatment but for $\tilde {I} = I_{ppERK}/I_{ERK1}$, \textbf {(D)} shows that both $\tilde {I}$ and $\log \tilde {I}$ have two modes, thus normalizing ppERK levels by total ERK1 maintains the bimodal structure both in $P(\log \tilde {I})$ and in $Q(\tilde {I})$. In (B) and (D), the vertical axis represents the functions $A, B_1,B_3$ according to the legend.\relax }{figure.caption.12}{}}
\citation{Parks2006}
\citation{Bagwell2016}
\bibstyle{cytA}
\bibdata{LogSpaceLatexPaper}
\bibcite{Vogel2016}{{1}{}{{}}{{}}}
\bibcite{Parks2006}{{2}{}{{}}{{}}}
\bibcite{Bagwell2016}{{3}{}{{}}{{}}}
\bibcite{Finak2010}{{4}{}{{}}{{}}}
\bibcite{Herzenberg2006}{{5}{}{{}}{{}}}
\bibcite{Novo2008}{{6}{}{{}}{{}}}
\bibcite{Friedman2006}{{7}{}{{}}{{}}}
\bibcite{Prill2015}{{8}{}{{}}{{}}}
\bibcite{Pal2015}{{9}{}{{}}{{}}}
\bibcite{Ridden2015}{{10}{}{{}}{{}}}
\bibcite{Mojtahedi2016}{{11}{}{{}}{{}}}
\bibcite{Erez2017}{{12}{}{{}}{{}}}
\bibcite{Brown2010}{{13}{}{{}}{{}}}
\bibcite{Prinz2010}{{14}{}{{}}{{}}}
\bibcite{Feinerman2008}{{15}{}{{}}{{}}}
\bibcite{Pelkmans2012}{{16}{}{{}}{{}}}
\bibcite{Cotari2013}{{17}{}{{}}{{}}}
\bibcite{Das2009}{{18}{}{{}}{{}}}
\bibcite{Cron2013}{{19}{}{{}}{{}}}
\bibcite{ONeill2013}{{20}{}{{}}{{}}}
\bibcite{Anchang2014}{{21}{}{{}}{{}}}
\bibcite{Finak2014}{{22}{}{{}}{{}}}
\bibcite{Saeys2016}{{23}{}{{}}{{}}}
\bibcite{Chen2016}{{24}{}{{}}{{}}}
\bibcite{Mukhopadhyay2000}{{25}{}{{}}{{}}}
\bibcite{Silverman1981}{{26}{}{{}}{{}}}
\bibcite{Johnsson2017}{{27}{}{{}}{{}}}
\bibcite{Hartigan1985}{{28}{}{{}}{{}}}
\bibcite{FlowJo}{{29}{}{{}}{{}}}
\bibcite{botev2010}{{30}{}{{}}{{}}}
\bibcite{Spencer2009}{{31}{}{{}}{{}}}
\bibcite{Koller2009}{{32}{}{{}}{{}}}
\bibcite{Ching2017}{{33}{}{{}}{{}}}
\bibcite{Filippi2016}{{34}{}{{}}{{}}}
\bibcite{NicPrice}{{35}{}{{}}{{}}}
\newlabel{eq:extremaP}{{6}{27}{Finding the extrema of a log-normal mixture}{equation.0.6}{}}
\newlabel{eq:QExtremaStrange}{{7}{27}{Finding the extrema of a log-normal mixture}{equation.0.7}{}}
\newlabel{eq:extremaQ}{{8}{27}{Finding the extrema of a log-normal mixture}{equation.0.8}{}}
\citation{NicPrice}
\citation{Feinerman2008}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces \textbf  {Testing Hartigan's p-value $p_u$ for unimodality on a weakly bimodal log-normal mixture.} The heat-map shows $p_u$ as a function of the number of bootstrap tests and number of events in each test, for $\sigma _1=0.4$ and $\sigma _2=0.8$ as in Fig.\nobreakspace  {}\ref  {fig:ExtremaSolutions}(top,middle). With less than $\sim 10^5$ events, Hartigan's test for this case may misidentify the number of peaks.\relax }}{29}{figure.caption.19}}
\newlabel{fig:CheckHartigan}{{6}{29}{\textbf {Testing Hartigan's p-value $p_u$ for unimodality on a weakly bimodal log-normal mixture.} The heat-map shows $p_u$ as a function of the number of bootstrap tests and number of events in each test, for $\sigma _1=0.4$ and $\sigma _2=0.8$ as in Fig.~\ref {fig:ExtremaSolutions}(top,middle). With less than $\sim 10^5$ events, Hartigan's test for this case may misidentify the number of peaks.\relax }{figure.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces {\bf  Test for weak dependence of ERK1 and activation status.} Whereas independence implies that $P(\mathop {\mathgroup \symoperators log}\nolimits ERK1) = P(\mathop {\mathgroup \symoperators log}\nolimits ERK1 \delimiter "026A30C Activation)$, in fact there is a weak dependence between them regardless of whether we employ a vertical (red, defined by threshold value $ppERK_*$) or a diagonal (grey) gate (the diagonal gate showing a weaker dependence); this is observed directly by noting that the different distributions in Fig.\nobreakspace  {}\ref  {S1_Fig} do not lie on top of each other. To quantify this difference, the inset shows the mutual information between $P(\mathop {\mathgroup \symoperators log}\nolimits ERK1)$ and $P(\mathop {\mathgroup \symoperators log}\nolimits ERK1 | Activation)$, with the circle pointing out the particular concentration of stimulus (out of all concentrations used in Ref.\nobreakspace  {}\cite  {Feinerman2008}) we chose to plot in this example. The chosen concentration has the highest mutual information, {\it  i.e.}, the lowest ability to discern between the active and inactive states.\relax }}{30}{figure.caption.21}}
\newlabel{S1_Fig}{{7}{30}{{\bf Test for weak dependence of ERK1 and activation status.} Whereas independence implies that $P(\log ERK1) = P(\log ERK1 \vert Activation)$, in fact there is a weak dependence between them regardless of whether we employ a vertical (red, defined by threshold value $ppERK_*$) or a diagonal (grey) gate (the diagonal gate showing a weaker dependence); this is observed directly by noting that the different distributions in Fig.~\ref {S1_Fig} do not lie on top of each other. To quantify this difference, the inset shows the mutual information between $P(\log ERK1)$ and $P(\log ERK1 | Activation)$, with the circle pointing out the particular concentration of stimulus (out of all concentrations used in Ref.~\cite {Feinerman2008}) we chose to plot in this example. The chosen concentration has the highest mutual information, {\it i.e.}, the lowest ability to discern between the active and inactive states.\relax }{figure.caption.21}{}}
